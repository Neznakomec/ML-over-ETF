{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "(1510,)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data = pandas.read_csv('features_SPY.csv', delimiter=',')\n",
    "data['Date'] = pandas.to_datetime(data['Date'])\n",
    "\n",
    "X = data.iloc[:, 1:23]\n",
    "#print(X)\n",
    "\n",
    "y = np.where(data['Return_2'] >= 0, 1.0, 0.0)\n",
    "print(y[:20])\n",
    "y = np.roll(y, -2) # yes it's future returns, but last values in array - are random trash!\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return_2 AverageVolume_2\n",
      "\n",
      "\n",
      "(1510, 6)\n"
     ]
    }
   ],
   "source": [
    "days = [0, 1, 2, 3, 5, 10, 20, 40, 60, 120, 250]\n",
    "\n",
    "#preparing features\n",
    "def getFeatures(X, days, period):\n",
    "    index_day = days.index(period)\n",
    "    featureCount = (1 + days[index_day - 1]) * 2 + 2;\n",
    "    \n",
    "    \n",
    "    #print(\"ii\",index_day)\n",
    "    return_key = \"Return_\" + str(period)\n",
    "    volume_key = \"AverageVolume_\" + str(period)\n",
    "    print(return_key, volume_key)\n",
    "\n",
    "    array = np.empty([0, featureCount])\n",
    "    for index, row in X.iterrows():\n",
    "        #if (index > 2): break;\n",
    "        features = np.empty(0)\n",
    "        #print(row)\n",
    "        column = X[return_key]\n",
    "        #print(column[index])\n",
    "        #print(\"i\",index)\n",
    "        #print(\"a\", features)\n",
    "        features = np.append(features, column[index])\n",
    "        #print(\"aa\", features)\n",
    "        for lag in range(1, days[index_day - 1] + 1):\n",
    "            #print(\"lag = %d\" % lag)\n",
    "            #numpy.append(features, value\n",
    "            if (index - lag >= 0):\n",
    "                features = np.append(features, column[index - lag])\n",
    "            else:\n",
    "                features = np.append(features, float(\"NaN\"))\n",
    "        \n",
    "        column = X[volume_key]\n",
    "        features = np.append(features, column[index])\n",
    "        for lag in range(1, days[index_day - 1] + 1):\n",
    "            #print(\"lag = %d\" % lag)\n",
    "            #numpy.append(features, value\n",
    "            if (index - lag >= 0):\n",
    "                features = np.append(features, column[index - lag])\n",
    "            else:\n",
    "                features = np.append(features, float(\"NaN\"))\n",
    "\n",
    "        column = X['DayOfWeek']\n",
    "        features = np.append(features, column[index])\n",
    "        column = X['DayOfMonth']\n",
    "        features = np.append(features, column[index])\n",
    "        \n",
    "        #print(features)\n",
    "        #https://stackoverflow.com/a/30305148\n",
    "        #print(features[None, :].shape)\n",
    "        #print(array.shape)\n",
    "        array = np.vstack([array, features[None, :]])\n",
    "        #print(\"array\",array)\n",
    "    print('\\n')\n",
    "    \n",
    "    return array\n",
    "\n",
    "print(getFeatures(X, days, 2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return_2 AverageVolume_2\n",
      "\n",
      "\n",
      "index =  RangeIndex(start=0, stop=1510, step=1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "      Feature0  Feature1     Feature2     Feature3  Feature4  Feature5\n",
      "0     0.011428 -0.014834  256726950.0  224754800.0       2.0      17.0\n",
      "1    -0.032661 -0.035755  270323850.0  255051550.0       1.0       6.0\n",
      "2     0.004041  0.011213  208322300.0  202053000.0       2.0       7.0\n",
      "3    -0.013739 -0.016527  158817450.0  155611900.0       1.0      23.0\n",
      "4    -0.007770 -0.007860  168925200.0  129434850.0       3.0       2.0\n",
      "...        ...       ...          ...          ...       ...       ...\n",
      "1052 -0.009724 -0.023326  257489150.0  228480000.0       4.0      29.0\n",
      "1053  0.004654  0.015897  166809100.0  185718600.0       4.0      20.0\n",
      "1054  0.017879  0.010813  105826300.0  156848150.0       4.0      23.0\n",
      "1055  0.010298  0.012168  136325450.0  131790850.0       4.0      18.0\n",
      "1056  0.018623  0.006132  156555550.0   88200450.0       3.0      13.0\n",
      "\n",
      "[1057 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "Xfeatures = getFeatures(X, days, 2)\n",
    "\n",
    "features_map = {\"Feature\" + str(i): Xfeatures[:,i] for i in range(0, Xfeatures[0].size)}\n",
    "#print(aa[\"column0\"].shape)\n",
    "Xfeatures = pandas.DataFrame(features_map)\n",
    "print(\"index = \", Xfeatures.index)\n",
    "print(type(Xfeatures))\n",
    "#XFeatures = pandas.Datafame(XFeatures)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xfeatures, y, \n",
    "                                      test_size=0.3, \n",
    "                                      random_state=241)\n",
    "\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#https://stackoverflow.com/questions/35723472/how-to-use-sklearn-fit-transform-with-pandas-and-return-dataframe-instead-of-num\n",
    "def scaleDataFrame(dataframe, debugPrint = False):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(dataframe)\n",
    "    dataframe = pandas.DataFrame(scaled_features, index=dataframe.index, columns=dataframe.columns)\n",
    "    \n",
    "    #check\n",
    "    if debugPrint == True:\n",
    "        for column in dataframe:\n",
    "            print(\"[%s] mean = %.4f, variance = %.4f\" % \n",
    "                  (column, dataframe[column].mean(), dataframe[column].var()))\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying C = 0.0001\n",
      "from 2019-11-13 16:17:40.377111\n",
      "[0.58 0.55 0.61]\n",
      "0.58\n",
      "to 2019-11-13 16:17:40.407110\n",
      "trying C = 0.001\n",
      "from 2019-11-13 16:17:40.416110\n",
      "[0.58 0.55 0.61]\n",
      "0.58\n",
      "to 2019-11-13 16:17:40.450136\n",
      "trying C = 0.01\n",
      "from 2019-11-13 16:17:40.455110\n",
      "[0.58 0.55 0.61]\n",
      "0.58\n",
      "to 2019-11-13 16:17:40.481133\n",
      "trying C = 0.1\n",
      "from 2019-11-13 16:17:40.486195\n",
      "[0.58 0.55 0.61]\n",
      "0.58\n",
      "to 2019-11-13 16:17:40.514111\n",
      "trying C = 1.0\n",
      "from 2019-11-13 16:17:40.519214\n",
      "[0.58 0.55 0.61]\n",
      "0.58\n",
      "to 2019-11-13 16:17:40.547112\n",
      "trying C = 10.0\n",
      "from 2019-11-13 16:17:40.554111\n",
      "[0.58 0.55 0.61]\n",
      "0.58\n",
      "to 2019-11-13 16:17:40.605111\n",
      "trying C = 100.0\n",
      "from 2019-11-13 16:17:40.612129\n",
      "[0.58 0.55 0.61]\n",
      "0.58\n",
      "to 2019-11-13 16:17:40.783114\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# C = 1000.0 algorithm hangs!\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "#C = {1.0}\n",
    "#grid = {'C': np.power(10.0, np.arange(-4, 0))}\n",
    "\n",
    "for penalty in C:\n",
    "    print(\"trying C = \" + str(penalty))\n",
    "    kf = KFold(n_splits=3, shuffle=False, random_state=241)\n",
    "    \n",
    "    X_train = scaleDataFrame(X_train, debugPrint = False)\n",
    "\n",
    "    clf = svm.SVC(C = penalty, kernel = 'linear', random_state=241)\n",
    "    N = 300\n",
    "    XX = X_train.iloc[:N, :]\n",
    "    yy = y_train[:N]\n",
    "    print(\"from\", datetime.now())\n",
    "    scores = cross_val_score(clf, XX, yy, scoring='accuracy', cv=kf)\n",
    "    print(scores)\n",
    "    print(scores.mean())\n",
    "    print(\"to\", datetime.now())\n",
    "    \n",
    "    continue;\n",
    "    for train_index, test_index in cv.split(X_train):\n",
    "        #clf = svm.SVC(kernel='linear', random_state=241)\n",
    "        clf = svm.SVC(C = 1.0, kernel = 'linear', verbose = True, random_state=241)\n",
    "        #XX = X_train.loc[train_index, ['Return_1', 'AverageVolume_1']]\n",
    "        XX = X_train.loc[train_index, :]\n",
    "        yy = y_train[train_index]\n",
    "        #print(train_index[:])\n",
    "        #print(X_train[0:13])\n",
    "        #print(XX.iloc[:20,:])\n",
    "        print(XX.iloc[:20, 0:1])\n",
    "        #print(yy[:10])\n",
    "        \n",
    "        print(\"XX type\",type(XX))\n",
    "        print(XX.shape)\n",
    "        print(yy.shape)\n",
    "        #XX.to_csv(\"XX.csv\", sep = \";\")\n",
    "        print(\"fit start\")\n",
    "        clf.fit(XX.iloc[:100, 0:2], yy[:100])\n",
    "        print(\"fit end\")\n",
    "        y_pred = clf.predict(X_train.iloc[:,0:2])\n",
    "        print(y_pred)\n",
    "        \n",
    "        #clf.fit(X_train[train_index], y_train[train_index])\n",
    "#gs = GridSearchCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "#gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from FeatureStore.ipynb\n",
      "[0. 1. 0. ... 0. 0. 1.]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import FeatureStore\n",
    "\n",
    "FeatureStore.getTrainDataset(2)\n",
    "FeatureStore.getTarget(period=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
