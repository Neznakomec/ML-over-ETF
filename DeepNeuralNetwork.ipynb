{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from FeatureStore.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import FeatureStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#https://stackoverflow.com/questions/35723472/how-to-use-sklearn-fit-transform-with-pandas-and-return-dataframe-instead-of-num\n",
    "def scaleDataFrame(dataframe, debugPrint = False):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(dataframe)\n",
    "    dataframe = pandas.DataFrame(scaled_features, index=dataframe.index, columns=dataframe.columns)\n",
    "    \n",
    "    #check\n",
    "    if debugPrint == True:\n",
    "        for column in dataframe:\n",
    "            print(\"[%s] mean = %.4f, variance = %.4f\" % \n",
    "                  (column, dataframe[column].mean(), dataframe[column].var()))\n",
    "    \n",
    "    return dataframe, scaler.mean_, scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "Period = [1, 2, 3, 5, 10, 20, 40, 60, 120, 250]\n",
    "Alpha = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "Layers = [(100,100), (100,100,100)]\n",
    "Activation = ['relu', 'logistic', 'tanh']\n",
    "# fill results with initial zero values\n",
    "for period in Period:\n",
    "    results[period] = {}\n",
    "    for alpha in Alpha:\n",
    "        results[period][alpha] = {}\n",
    "        for activation in Activation:\n",
    "            results[period][alpha][activation] = {}\n",
    "            for layer in Layers:\n",
    "                 results[period][alpha][activation][layer] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying Alpha = 1.000000, period = 0, function = relu, layer config (100, 100)\n",
      "accuracy= 0.7842974718859989\n",
      "trying Alpha = 1.000000, period = 0, function = relu, layer config (100, 100, 100)\n",
      "accuracy= 0.7861940939136406\n",
      "trying Alpha = 1.000000, period = 0, function = logistic, layer config (100, 100)\n",
      "accuracy= 0.5591064683663833\n",
      "trying Alpha = 1.000000, period = 0, function = logistic, layer config (100, 100, 100)\n",
      "accuracy= 0.5591064683663833\n",
      "trying Alpha = 1.000000, period = 0, function = tanh, layer config (100, 100)\n",
      "accuracy= 0.7890269551034423\n",
      "trying Alpha = 1.000000, period = 0, function = tanh, layer config (100, 100, 100)\n",
      "accuracy= 0.7842947892522963\n",
      "trying Alpha = 1.000000, period = 0, function = relu, layer config (100, 100)\n",
      "accuracy= 0.7842974718859989\n",
      "trying Alpha = 1.000000, period = 0, function = relu, layer config (100, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#Alpha = [0.1]; Period = [1]\n",
    "#C = {1.0}\n",
    "#grid = {'C': np.power(10.0, np.arange(-4, 0))}\n",
    "\n",
    "sigma1 = 0\n",
    "mu1 = 0\n",
    "clf1 = 0\n",
    "accs = {}\n",
    "\n",
    "\n",
    "            \n",
    "for period in Period:\n",
    "    X_train = FeatureStore.getTrainDataset(period)\n",
    "    y_train = FeatureStore.getTrainTarget(period)\n",
    "    \n",
    "    X_train, sigma, mu = scaleDataFrame(X_train, debugPrint = False)\n",
    "    #print(sigma)\n",
    "    #print(mu)\n",
    "\n",
    "    for alpha in Alpha:\n",
    "        for activation in Activation:\n",
    "            for layer in Layers:\n",
    "                print(\"trying Alpha = %f, period = %d, function = %s, layer config %s\" \n",
    "                      % (alpha, period, activation, layer))\n",
    "                kf = KFold(n_splits=3, shuffle=False, random_state=241)\n",
    "\n",
    "                clf = MLPClassifier(hidden_layer_sizes = layer, activation=activation, solver='sgd', \n",
    "                                    alpha = alpha, max_iter = 100000, random_state=241)\n",
    "                if (period == 40):\n",
    "                    sigma1 = sigma\n",
    "                    mu1 = mu\n",
    "                    clf1 = clf\n",
    "                #N = 800\n",
    "                #XX = X_train.iloc[:N, :]\n",
    "                #yy = y_train[:N]\n",
    "                XX = X_train\n",
    "                yy = y_train\n",
    "                #print(X_train.shape)\n",
    "                #print(y_train.shape)\n",
    "                #print(\"from\", datetime.now())\n",
    "                scores = cross_val_score(clf, XX, yy, scoring='accuracy', cv=kf)\n",
    "\n",
    "                #print(\"spent iterations %d\" % (clf.n_iter_))\n",
    "                #print(clf)\n",
    "                #print(vars(clf))\n",
    "                #print(clf.n_iter_)\n",
    "                #print(scores)\n",
    "                print(\"accuracy=\", scores.mean())\n",
    "                results[period][alpha][activation] = scores.mean() \n",
    "                #print(\"to\", datetime.now())\n",
    "                #accs[period].append(scores.mean())\n",
    "                if period in accs and not (accs[period] is None):\n",
    "                    accs[period].append(scores.mean())\n",
    "                else:\n",
    "                    accs[period] = [scores.mean()]\n",
    "        \n",
    "for k in accs:\n",
    "    accs[k] = np.max(accs[k])\n",
    "\n",
    "#print(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in accs.items():\n",
    "    print(\"%d;%f\" % (k, v))\n",
    "    \n",
    "\n",
    "print(clf1, sigma1, mu1)\n",
    "print(results)\n",
    "\n",
    "import json\n",
    "with open('resultDNN.json', 'w') as fp:\n",
    "    json.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def backtestStrategy():\n",
    "    #trying Alpha = 0.100000, period = 40, function = relu\n",
    "    period = 40\n",
    "    penalty = 0.1\n",
    "    activation = 'relu'\n",
    "    \n",
    "    X_train = FeatureStore.getTrainDataset(period)\n",
    "    y_train = FeatureStore.getTrainTarget(period)\n",
    "    \n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100, 100), activation=activation, solver='sgd', \n",
    "                    alpha = penalty, max_iter = 100000, random_state=241)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    X_test  = FeatureStore.getTestDataset(period)\n",
    "    y_test  = FeatureStore.getTestTarget(period)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print(clf.score(X_test, y_test))\n",
    "    \n",
    "    pass\n",
    "\n",
    "backtestStrategy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
