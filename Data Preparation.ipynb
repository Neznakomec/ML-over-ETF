{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date        Open        High         Low       Close   Adj Close  \\\n",
      "0    2009-12-31  112.769997  112.800003  111.389999  111.440002   91.689629   \n",
      "1    2010-01-04  112.370003  113.389999  111.510002  113.330002   93.244675   \n",
      "2    2010-01-05  113.260002  113.680000  112.849998  113.629997   93.491486   \n",
      "3    2010-01-06  113.519997  113.989998  113.430000  113.709999   93.557304   \n",
      "4    2010-01-07  113.500000  114.330002  113.180000  114.190002   93.952278   \n",
      "...         ...         ...         ...         ...         ...         ...   \n",
      "1758 2016-12-23  225.429993  225.720001  225.210007  225.710007  214.288986   \n",
      "1759 2016-12-27  226.020004  226.729996  226.000000  226.270004  214.820618   \n",
      "1760 2016-12-28  226.570007  226.589996  224.270004  224.399994  213.045227   \n",
      "1761 2016-12-29  224.479996  224.889999  223.839996  224.350006  212.997772   \n",
      "1762 2016-12-30  224.729996  224.830002  222.729996  223.529999  212.219269   \n",
      "\n",
      "         Volume  \n",
      "0      90637900  \n",
      "1     118944600  \n",
      "2     111579900  \n",
      "3     116074400  \n",
      "4     131091100  \n",
      "...         ...  \n",
      "1758   36697800  \n",
      "1759   42672500  \n",
      "1760   64095000  \n",
      "1761   48696100  \n",
      "1762  108998300  \n",
      "\n",
      "[1763 rows x 7 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-648a6363466f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"features_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#, sep=';'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SPY.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTART_DATE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEND_DATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-110-648a6363466f>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(filename, start_date, end_date)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#return_data = pandas.concat(return_features, axis=1, keys=[s.name for s in return_features])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mreturn_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mvolume_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvolume_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreturn_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreturn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvolume_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#    for column in volume_features:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All objects passed were None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# consolidate data & figure out what our result ndim is going to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "START_DATE = '2011-01-01'\n",
    "END_DATE = '2017-01-01'\n",
    "def preprocess(filename, start_date, end_date):\n",
    "    TradingDaysPeriods = [1, 2, 3, 5, 10, 20, 40, 60, 120, 250]\n",
    "    \n",
    "    data = pandas.read_csv(filename, delimiter=',')\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    print(data)\n",
    "\n",
    "    return_features = pandas.DataFrame()\n",
    "    volume_features = []\n",
    "    for period in TradingDaysPeriods:\n",
    "        column = data['Adj Close'].pct_change(periods = period)\n",
    "        column.rename(\"Return_\" + str(period), inplace = True)\n",
    "        return_features.append(column)\n",
    "        \n",
    "        column = data['Volume'].rolling(period).mean()\n",
    "        column.rename(\"AverageVolume_\" + str(period), inplace = True)\n",
    "        volume_features.append(column)\n",
    "    #return_data = pandas.concat(return_features, axis=1, keys=[s.name for s in return_features])\n",
    "    return_data = return_features\n",
    "    volume_data = pandas.concat(volume_features, axis=1, keys=[s.name for s in return_features])\n",
    "    out_data = pandas.concat([return_data, volume_data], axis=1)\n",
    "#    for column in volume_features:\n",
    "#        df.insert(len(df.columns), s.name,s)\n",
    "    #df = pandas.DataFrame(df, df2)\n",
    "    #df['Date'] = data['Date']\n",
    "    out_data.insert(0, 'Date', data['Date'])\n",
    "    out_data['DayOfWeek'] = out_data['Date'].dt.dayofweek\n",
    "    out_data['DayOfMonth'] = out_data['Date'].dt.day\n",
    "    #https://stackoverflow.com/questions/29370057/select-dataframe-rows-between-two-dates\n",
    "    mask = (out_data['Date'] >= start_date) & (out_data['Date'] <= end_date)\n",
    "    print(out_data.loc[mask])\n",
    "    out_data = out_data.loc[mask]\n",
    "    print(out_data)\n",
    "    out_data.to_csv(path_or_buf = \"features_\" + filename) #, sep=';'\n",
    "    \n",
    "preprocess('SPY.csv', START_DATE, END_DATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
